#!/usr/bin/env python3
"""
Fresha.com Scanner ‚Äî –ø—Ä–æ—Å—Ç–∞—è –≤–µ—Ä—Å–∏—è
–®–∞–≥ 1: –ü—Ä–æ—Å—Ç–æ –æ—Ç–∫—Ä—ã–≤–∞–µ–º –±—Ä–∞—É–∑–µ—Ä
–®–∞–≥ 2: –Æ–∑–µ—Ä –ª–æ–≥–∏–Ω–∏—Ç—Å—è
–®–∞–≥ 3: –°–∫–∞–Ω–∏—Ä—É–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã
"""

import asyncio
import json
import os
import re
import random
from datetime import datetime
from pathlib import Path

from camoufox.async_api import AsyncCamoufox

# –ü–∞–ø–∫–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
OUTPUT_DIR = Path(__file__).parent / "output"
PAGES_DIR = OUTPUT_DIR / "pages"
API_DIR = OUTPUT_DIR / "api"
ANALYSIS_DIR = OUTPUT_DIR / "analysis"


def setup_dirs():
    """–°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫–∏"""
    for d in [OUTPUT_DIR, PAGES_DIR, API_DIR, ANALYSIS_DIR]:
        d.mkdir(parents=True, exist_ok=True)


async def save_page(page, name: str):
    """–°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É"""
    safe_name = re.sub(r'[^\w\-]', '_', name)[:50]
    page_dir = PAGES_DIR / safe_name
    page_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"  üì∏ –°–∫—Ä–∏–Ω—à–æ—Ç...")
    await page.screenshot(path=str(page_dir / "screenshot.png"), full_page=True)
    
    print(f"  üìÑ HTML...")
    html = await page.content()
    (page_dir / "page.html").write_text(html, encoding="utf-8")
    
    print(f"  üìù URL: {page.url}")
    meta = {"name": name, "url": page.url, "saved_at": datetime.now().isoformat()}
    (page_dir / "meta.json").write_text(json.dumps(meta, indent=2), encoding="utf-8")
    
    return {"name": name, "url": page.url, "folder": str(page_dir)}


async def get_nav_links(page):
    """–ù–∞—Ö–æ–¥–∏–º —Å—Å—ã–ª–∫–∏ –≤ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏"""
    links = await page.evaluate("""
        () => {
            const items = [];
            const seen = new Set();
            document.querySelectorAll('nav a, [class*="sidebar"] a, [class*="menu"] a, [role="navigation"] a, aside a').forEach(a => {
                if (a.href && !seen.has(a.href) && a.href.startsWith('http')) {
                    seen.add(a.href);
                    items.push({
                        text: a.textContent?.trim().slice(0, 50) || 'unknown',
                        href: a.href
                    });
                }
            });
            return items;
        }
    """)
    return links


async def main():
    print("ü¶ä Fresha Scanner ‚Äî –∑–∞–ø—É—Å–∫")
    print("=" * 50)
    
    setup_dirs()
    
    # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ ‚Äî —Ç–æ–ª—å–∫–æ headless=False
    print("\nüåê –ó–∞–ø—É—Å–∫–∞—é –±—Ä–∞—É–∑–µ—Ä...")
    
    async with AsyncCamoufox(headless=False) as browser:
        page = await browser.new_page()
        
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º Google
        print("üìç –û—Ç–∫—Ä—ã–≤–∞—é Google...")
        await page.goto("https://www.google.com/")
        
        print("\n" + "=" * 50)
        print("üëÜ –¢–í–û–ô –•–û–î:")
        print("1. –ü–µ—Ä–µ–π–¥–∏ –Ω–∞ Fresha –∏ –∑–∞–ª–æ–≥–∏–Ω—å—Å—è")
        print("2. –î–æ–π–¥–∏ –¥–æ –¥–∞—à–±–æ—Ä–¥–∞")
        print("3. –ù–∞–∂–º–∏ Enter –∑–¥–µ—Å—å")
        print("=" * 50)
        
        input("\n‚èé Enter –∫–æ–≥–¥–∞ –≥–æ—Ç–æ–≤...")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É (–¥–∞—à–±–æ—Ä–¥)
        pages_saved = []
        print("\nüîç –°–∫–∞–Ω–∏—Ä—É—é —Ç–µ–∫—É—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É...")
        result = await save_page(page, "dashboard")
        pages_saved.append(result)
        
        # –ò—â–µ–º –Ω–∞–≤–∏–≥–∞—Ü–∏—é
        print("\nüìã –ò—â—É —Å—Å—ã–ª–∫–∏ –≤ –º–µ–Ω—é...")
        nav_links = await get_nav_links(page)
        print(f"   –ù–∞–π–¥–µ–Ω–æ: {len(nav_links)} —Å—Å—ã–ª–æ–∫")
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ Fresha
        fresha_links = [l for l in nav_links if "fresha.com" in l["href"]]
        print(f"   Fresha —Å—Å—ã–ª–æ–∫: {len(fresha_links)}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –Ω–∞—à–ª–∏
        for i, link in enumerate(fresha_links[:10]):
            print(f"   {i+1}. {link['text']}")
        
        # –°–ø—Ä–∞—à–∏–≤–∞–µ–º –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –ª–∏
        print("\n" + "=" * 50)
        cont = input("–°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã? (y/n): ").strip().lower()
        
        if cont == 'y':
            visited = {page.url}
            
            for link in fresha_links[:20]:
                href = link["href"]
                if href in visited:
                    continue
                visited.add(href)
                
                name = link["text"] or "page"
                print(f"\nüîç –°–∫–∞–Ω–∏—Ä—É—é: {name}")
                
                # –°–ª—É—á–∞–π–Ω–∞—è –ø–∞—É–∑–∞
                delay = random.uniform(2, 4)
                print(f"   ‚è≥ –ü–∞—É–∑–∞ {delay:.1f} —Å–µ–∫...")
                await asyncio.sleep(delay)
                
                try:
                    await page.goto(href, timeout=30000)
                    await asyncio.sleep(2)  # –î–∞—ë–º –∑–∞–≥—Ä—É–∑–∏—Ç—å—Å—è
                    result = await save_page(page, name)
                    pages_saved.append(result)
                except Exception as e:
                    print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞: {e}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á—ë—Ç
        report = {
            "scanned_at": datetime.now().isoformat(),
            "pages": pages_saved,
            "total": len(pages_saved)
        }
        report_path = ANALYSIS_DIR / "report.json"
        report_path.write_text(json.dumps(report, indent=2), encoding="utf-8")
        
        print("\n" + "=" * 50)
        print(f"‚úÖ –ì–û–¢–û–í–û!")
        print(f"   –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {len(pages_saved)}")
        print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {OUTPUT_DIR}")
        print("=" * 50)
        
        input("\n‚èé Enter —á—Ç–æ–±—ã –∑–∞–∫—Ä—ã—Ç—å –±—Ä–∞—É–∑–µ—Ä...")


if __name__ == "__main__":
    asyncio.run(main())
